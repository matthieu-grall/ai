# Methodological tools for artificial intelligence (AI)

This project aims to **provide methodological tools for managing AI-related risks**.


It comprises a set of documents, developed collaboratively and under continuous improvement, designed to help organizations manage AI-related risks:

1. examples of micro-usecases;

2. harmonized trust criteria;

3. harmonized best practices;

4. a risk management method.


It is **intended to fit in with existing approaches within organizations**, notably system certification processes. However, some or all of these documents may also be used directly, together or separately.

The backlog is currently the following (maybe one day)...:
- use trust criteria to estimate risks on micro-usecases;
- translate documents in english, once they're mature enough.

[![CC BY 4.0][cc-by-shield]][cc-by]

Those documents are licensed under a 
[Creative Commons Attribution 4.0 International License][cc-by].

[![CC BY 4.0][cc-by-image]][cc-by]

[cc-by]: http://creativecommons.org/licenses/by/4.0/
[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png
[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg
