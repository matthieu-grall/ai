# Methodological tools for artificial intelligence (AI)

This project aims to **provide methodological tools for managing AI-related risks**.
A presentation is provided in [.pdf](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20Pr%C3%A9sentation.pdf) and [.pptx](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20Pr%C3%A9sentation.pptx) formats.


It comprises a set of documents, developed collaboratively and under continuous improvement:
1. [a risk management method](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20M%C3%A9thode.md);
2. [harmonized trust criteria](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20Crit%C3%A8res%20de%20confiance.md);
3. [harmonized best practices](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20Bonnes%20pratiques.md);
4. [examples of usecases](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20Cas%20d'usages.md);
5. [reference documents](https://github.com/matthieu-grall/ai/blob/main/IA%20-%20Gestion%20des%20risques%20-%20Documents%20de%20r%C3%A9f%C3%A9rence.md).

It is **intended to fit in with existing approaches within organizations**, notably system certification processes. However, some or all of these documents may also be used directly, together or separately.

The **strategic plan (and backlog)** is currently the following*:
| <center>**Priority**</center> | <center>**Documents**</center> | <center>**Main added value**</center> | <center>**Main limits**</center> | <center>**Main actions on documents**</center> | <center>**Main actions on references**</center> | <center>**Main actions in organizations**</center> | 
| --- | --- | --- | --- | --- | --- | --- | 
| - | General | Maybe the only global approach (needed by organizations) | Institutions not legitimate on global scope</br>Currently only in French | (M) Validate the general value</br>(S) Promote the approach (e.g. LINKEDIN, CESIN, Club EBIOS)</br>(S) Translate into English | None | (M) Test the approach | 
| 1 | Method | 1. Huge | Qualification not mature enough | (M) Consolidate qualification</br>(S) Develop the context establisment (description of the AI scope)</br>(M) Add redirection to other reference documents (e.g. taxonomy of attacks proposed by Hub France IA) | (S) Improve ISO and EU projects and standards | (M) Test the method | 
| 2 | Trust criteria | 2. High | No worldwide consensus | (M) Validate | (S) Propose convergence (e.g. in [ISO/IEC 42001]) | None | 
| 3 | Best practices | 2. High | Very wide and complicated | (S) Add "tags" for satisfaction criteria/proof</br>(S) Add "tags" to state who has to implement/answer</br>(M) Refine practices that contained in reference documents OR only redirect to them</br>(M) Add redirection to other reference documents (e.g. controls proposed by Hub France IA) | (C) Determine the most effective way to converge (e.g. thru MITRE) | (S) Test the statement of applicability | 
| 4 | Micro-usecases | 3. Low | Controversial</br>Difficult to use and maintain | (S) Organize usecases</br>(C) Apply qualification (first step of the method) to each usecase</br>(M) Check if [ISO/IEC 24030] can bring added value | (C) Contribute to [ISO/IEC 24030] | (S) Test | 

(M) Must have | (S) Should have | (C) Could Have | (W) Won't have


[![CC BY 4.0][cc-by-shield]][cc-by]

Those documents are licensed under a 
[Creative Commons Attribution 4.0 International License][cc-by].

[![CC BY 4.0][cc-by-image]][cc-by]

[cc-by]: http://creativecommons.org/licenses/by/4.0/
[cc-by-image]: https://i.creativecommons.org/l/by/4.0/88x31.png
[cc-by-shield]: https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg
