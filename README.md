# Methodological tools for artificial intelligence (AI)

This project aims to **provide methodological tools for managing AI-related risks**.


It comprises a set of documents, developed collaboratively and under continuous improvement, designed to help organizations manage AI-related risks:

1. examples of micro-usecases;

2. harmonized trust criteria;

3. harmonized best practices;

4. a risk management method.


It is **intended to fit in with existing approaches within organizations**, notably system certification processes. However, some or all of these documents may also be used directly, together or separately.

The backlog is currently the following (maybe one day)...:
- use trust criteria to estimate risks on micro-usecases;
- translate documents in english, once they're mature enough.
